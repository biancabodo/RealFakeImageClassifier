# -*- coding: utf-8 -*-
"""ImageClassifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ng9IvTmcg30h9myEvCcCiyoCaH3UfFGK
"""

from google.colab import drive
drive.mount('/content/gdrive/')

from google.colab import files
files.upload()

!pip install -q kaggle
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!ls ~/.kaggle
!chmod 600 /root/.kaggle/kaggle.json

!kaggle datasets download -d ciplab/real-and-fake-face-detection --force

!unzip \*.zip  && rm *.zip

# Commented out IPython magic to ensure Python compatibility.
# %mv real_and_fake_face/ input_data
# %ls

import pathlib

data_dir = pathlib.Path('/content/input_data/')
training_fake = pathlib.Path('/content/input_data/training_fake')
training_real = pathlib.Path('/content/input_data/training_real')

!pip install mtcnn

from matplotlib import pyplot
from matplotlib.patches import Rectangle
from mtcnn.mtcnn import MTCNN
from PIL import Image

filename = '/content/input_data/training_fake/mid_137_1011.jpg'

def draw_image_with_boxes(filename, result_list):
    # load the image
    data = pyplot.imread(filename)
    # plot the image
    pyplot.imshow(data)
    # get the context for drawing boxes
    ax = pyplot.gca()
    # plot each box
    for result in result_list:
        # get coordinates
        x, y, width, height = result['box']
        # create the shape
        rect = Rectangle((x, y), width, height, fill=False, color='red')
        # draw the box
        ax.add_patch(rect)
    # show the plot
    pyplot.show()
    return(x,y,x+width,y+height)
    
detector = MTCNN()
# detect faces in the image
pixels = pyplot.imread(filename)
print(pixels)
faces = detector.detect_faces(pixels)
# display faces on the original image
draw_image_with_boxes(filename, faces)

# Commented out IPython magic to ensure Python compatibility.
# %mkdir data
# %cd data/
# %mkdir fake
# %mkdir real

# Commented out IPython magic to ensure Python compatibility.
# %cd ..

from matplotlib import pyplot
from matplotlib.patches import Rectangle
from mtcnn.mtcnn import MTCNN
from PIL import Image
import os 

## change the folder name accordingly for training and testing
path = '/content/input_data/'

folders = os.listdir(path)
print(folders)
#folders = folders[1:] ## [1:] to remove .ds_store folder if it is made automatically otherwise just use folder

## Iterate over the folder and detect and crop faces and save them in respective folder
for subs in folders:
    for files in os.listdir(path+subs):
        try:
            if 'fake' in path+subs+files and 'jpg' in path+subs+files:
                print(path+subs+'/'+files)
                pixels = pyplot.imread(path+subs+'/'+files)
                faces = detector.detect_faces(pixels)
                x, y, width, height = faces[0]['box']
                #coordinates = tuple(faces[0]['box'])
                Image.fromarray(pixels).crop((x, y, x + width, y + height)).save('/content/data/fake/'+files)
            elif 'real' in path+subs+files and 'jpg' in path+subs+files:
                print(path+subs+'/'+files)
                pixels = pyplot.imread(path+subs+'/'+files)
                faces = detector.detect_faces(pixels)
                x, y, width, height = faces[0]['box']
                #coordinates = tuple(faces[0]['box'])
                Image.fromarray(pixels).crop((x, y, x + width, y + height)).save('/content/data/real/'+files)
        except (IndexError or SystemError):
            print('Face Not Found')

from keras.models import Sequential 
from keras.layers import Conv2D,MaxPool2D,Flatten,Dense,Dropout
from keras.preprocessing.image import ImageDataGenerator

from keras.utils import to_categorical
import matplotlib.pyplot as plt
import numpy as np
import os
import PIL
import tensorflow as tf

from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential

model = Sequential()

model.add(Conv2D(32,(3,3),input_shape = (200,200,3),activation = 'relu',padding='same',))
model.add(MaxPool2D(pool_size=(2,2)))
model.add(Dropout(0.2))

model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))
model.add(MaxPool2D((2, 2)))
model.add(Dropout(0.2))

model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))
model.add(MaxPool2D((2, 2)))
model.add(Dropout(0.2))

model.add(Flatten())

model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))

model.compile(optimizer = 'adam',loss = 'binary_crossentropy',metrics = ['accuracy'])

datagen = ImageDataGenerator(rescale=1.0/255.0,
                             validation_split = 0.2
                             
                             )

train = datagen.flow_from_directory('/content/data/',
                                    classes={
                                        'fake':1,
                                        'real':0
                                    },
                                    class_mode='binary',
                                    batch_size=64,
                                    target_size=(200,200),
                                    subset = 'training')

val = datagen.flow_from_directory('/content/data/',
                                  classes={
                                        'fake':1,
                                        'real':0
                                    },
                                    class_mode='binary',
                                    batch_size=64,
                                    target_size=(200,200),
                                    subset = 'validation')
print(val)

history = model.fit_generator(train,
                              validation_data=(val),
                              epochs = 50,
                              steps_per_epoch=len(train),
                              validation_steps=val.samples
                              )

models_path = '/content/gdrive/MyDrive/uclais/dataset/dataset/data/dataset/dataset/test/models/'
model_json = model.to_json()
with open(models_path+'model.json','w') as json_file:
    json_file.write(model_json)

model.save_weights(models_path+'model.h5')

# Commented out IPython magic to ensure Python compatibility.
# %mkdir /content/final_test/
# %ls

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/final_test/
# %rm *.jpg
# %ls

from keras.models import load_model, model_from_json
from PIL import Image
import json
import numpy as np 
from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
import pandas as pd
import shutil

folder_path = '/content/gdrive/MyDrive/uclais/dataset/dataset/data/dataset/dataset/test/test/'
cropped_faces_test_path = '/content/final_test/'
model_json_path = '/content/gdrive/MyDrive/uclais/dataset/dataset/data/dataset/dataset/test/models/model.json'
model_weights_path = '/content/gdrive/MyDrive/uclais/dataset/dataset/data/dataset/dataset/test/models/model.h5'

json_file = open(model_json_path,'r')
loaded_model = json_file.read()
json_file.close()

model = model_from_json(loaded_model)
model.load_weights(model_weights_path)

img_width, img_height = 200,200

# Load Image 
images = []
folder_images = os.listdir(folder_path)

for img in folder_images:
  try:
      print(img)
      pixels = pyplot.imread(folder_path + img)
      faces = detector.detect_faces(pixels)
      x, y, width, height = faces[0]['box']
      Image.fromarray(pixels).crop((x, y, x + width, y + height)).save(cropped_faces_test_path+img)
  except(IndexError or SystemError):
      print('bagi pula in ' + img)
      shutil.move(folder_path + img, cropped_faces_test_path)


cropped_img_list = os.listdir(cropped_faces_test_path)
cropped_img_list.sort(key=lambda file_name: int(file_name.split('.')[0]))
print(cropped_img_list)
for img in cropped_img_list:
    img = os.path.join(cropped_faces_test_path, img)
    img = image.load_img(img, target_size=(img_width, img_height))
    img = image.img_to_array(img)
    img = np.expand_dims(img, axis=0)
    
    # im = np.asarray(im)
    #img = np.reshape(img,(1,img.shape[0],img.shape[1],img.shape[2]))
    images.append(img)


# stack up images list to pass for prediction
images = np.vstack(images)
classes = model.predict_classes(images, batch_size=10)
print(classes)
for i,_ in enumerate(classes):
  classes[i] = 1 - classes[i]

print(classes)

result_df = pd.DataFrame()
result_df["filename"] = list(cropped_img_list)
result_df["label"] = classes

result_df.head()
result_df.to_excel(models_path+'subms2.xlsx')

